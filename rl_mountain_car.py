# -*- coding: utf-8 -*-
"""RL: Mountain Car

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1soQwlxfeJJYlDW0TicnUieO_E1oywkxS
"""

import torch
import torch.optim as optim
import torch.nn.functional as F
import torch.nn as nn
import torchvision.datasets as dsets
import numpy as np
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
import torchvision
import matplotlib.pyplot as plt
import random

import json
import pandas as pd
import os.path
import xml.etree.ElementTree as ET
import PIL
from google.colab import drive

import itertools
from itertools import product

torch.manual_seed(0)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

def get_tiling_points(start, tile_length, bound):
  tiling_points=[]
  left_bound=bound[0]
  right_bound=bound[1]
  if start>left_bound:
    tiling_points.append(left_bound)
    tiling_points.append(start)
  else:
    tiling_points.append(start)
  count=1
  while True:
    point=start+count*tile_length
    if point>=right_bound:
      tiling_points.append(right_bound)
      break
    else:
      tiling_points.append(point)
      count+=1
  return tiling_points

def get_tiling_grids(tiling_points_dim):
  size=len(tiling_points_dim)
  tiling_grids_dim=torch.zeros(size-1, 2).to(device)
  for idx in range(size-1):
    left=tiling_points_dim[idx]
    right=tiling_points_dim[idx+1]
    tiling_grids_dim[idx,:]=torch.FloatTensor([left, right])
  return tiling_grids_dim

def combine_tiling_grids(tiling_grids):
  tg_list=[]
  for tiling_grid in tiling_grids:
    tg_list.append(tiling_grid.cpu().numpy())
  tiling=list(itertools.product(*list(tg_list)))
  tiling=torch.FloatTensor(tiling).to(device)
  return tiling

def find_idx(state, tiling):
  for idx, grid in enumerate(tiling):
    n_dim=grid.size(0)
    flags=torch.zeros(n_dim).long().to(device)
    for dim in range(n_dim):
      left=grid[dim,0]
      right=grid[dim,1]
      if state[dim]>=left and state[dim]<=right:
        flags[dim]=1
    if torch.sum(flags)==n_dim:
      return idx

#grid tile coding: binary coarse coding for continuous state-space
class Tile_Coding():
  def __init__(self, s_dim, bounds, n_tilings, n_tiles):
    self.s_dim=s_dim #dimension of the state-space
    self.bounds=bounds #bounds of each dimension, size=s_dim
    self.n_tilings=n_tilings #No. of tilings
    self.n_tiles=n_tiles #No. of tiles of each dimension
    self.tilings, self.n_features_list=self.get_tilings()
    self.n_features=torch.sum(self.n_features_list).item()
  
  def get_tilings(self):
    #for each tiling:
    tilings=[]
    n_features_list=torch.zeros(self.n_tilings).long().to(device)
    for tilings_idx in range(self.n_tilings):
      #for each dimension (state-space)
      tiling_grids=[]
      #get tiling grids for each dimension
      for dim in range(self.s_dim):
        #sizes of a tiling in each dimension
        bound=self.bounds[dim]
        n_tile=self.n_tiles[dim]
        bound_length=bound[1]-bound[0]
        tile_length=bound_length/n_tile
        offset_length=tile_length/self.n_tilings
        start=bound[0]+tilings_idx*offset_length
        #grid points of a tiling for each dimension
        tiling_points_dim=get_tiling_points(start, tile_length, bound)
        #grid foramt (left, right) of a tiling for each dimension
        tiling_grids_dim=get_tiling_grids(tiling_points_dim)
        tiling_grids.append(tiling_grids_dim)
      #using constructed grids-> construct tiling
      tiling=combine_tiling_grids(tiling_grids)
      tilings.append(tiling)
      n_features_list[tilings_idx]=tiling.size(0)
    return tilings, n_features_list
      
  #return feature vector for "state"
  #feature_vector for s,a -> feat_vector for s'? ->
  def get_feature_vector(self, state):
    idx_list=[]
    #find index in each tiling
    for tiling in self.tilings:
      idx=find_idx(state, tiling)
      idx_list.append(idx)
    #transform idx list into feature vector
    sum=0
    feature_vector=torch.zeros(self.n_features).to(device)
    for tilings_idx, idx in enumerate(idx_list):
      f_index=sum+idx
      feature_vector[f_index]=1
      sum+=(self.n_features_list[tilings_idx])
    return feature_vector

class Mountain_Car(nn.Module):
  def __init__(self, s_dim, bounds, n_tilings, n_tiles):
    super(Mountain_Car, self).__init__()
    self.bounds=bounds
    #tile coding class
    self.tile_coding=Tile_Coding(s_dim, self.bounds, n_tilings, n_tiles)
    self.n_features=self.tile_coding.n_features
    self.actions_list=[1,0,-1]
    self.a_idx_list=[0,1,2]
    self.len_a=len(self.actions_list)
    self.len_f=self.n_features+self.len_a
    self.weight=torch.zeros(self.len_f).to(device)
    self.weight_init()
  
  def weight_init(self):
    self.weight=torch.zeros(self.len_f).uniform_(-1/np.sqrt(self.len_f), 1/np.sqrt(self.len_f)).to(device)
    return
    
  def progression(self, state, a_idx):
    loc_i=state[0]
    vel_i=state[1]
    action=self.actions_list[a_idx]
    #get final velocity first
    vel_f=vel_i+0.001*action-0.0025*np.cos(3*loc_i)
    #bound the velocity
    if vel_f>self.bounds[1][1]:
      vel_f=self.bounds[1][1]
    elif vel_f<self.bounds[1][0]:
      vel_f=self.bounds[1][0]
    #get final location
    loc_f=loc_i+vel_f
    #bound the location
    if loc_f>self.bounds[0][1]:
      loc_f=self.bounds[0][1]
    elif loc_f<self.bounds[0][0]:
      loc_f=self.bounds[0][0]
    #if final state crosses bounds
    if loc_f==self.bounds[0][1]:
      termination=True
    elif loc_f==self.bounds[0][0]:
      vel_f=0
      termination=False
    else:
      termination=False
    #final state
    state_f=[loc_f, vel_f]
    reward=-1
    return state_f, reward, termination
  

  def e_greedy_selection(self, state, eps):
    q_vector=torch.zeros(self.len_a).to(device)
    probability=[eps/self.len_a for _ in range(self.len_a)]
    for a_idx in self.a_idx_list:
      q_vector[a_idx]=self.get_action_value(state, a_idx)
    argmax_idx=torch.argmax(q_vector, dim=0)
    probability[argmax_idx]+=1-eps
    a_idx=random.choices(self.a_idx_list, probability)[0]
    return a_idx
  
  #binary feature vector
  def get_feature_vector(self, state, a_idx):
    feature_vector=torch.zeros(self.len_f).to(device)
    fv=self.tile_coding.get_feature_vector(state)
    feature_vector[:self.n_features]=fv
    feature_vector[self.n_features+a_idx]=1
    return feature_vector
  
  def get_action_value(self, state, a_idx):
    feature_vector=self.get_feature_vector(state, a_idx)
    action_value=torch.dot(feature_vector, self.weight)
    return action_value
  
  def n_step_Sarsa(self, n, iter, step_size):
    gamma=1.
    self.weight_init()
    for epoch in range(1, iter+1):
      loc_start=random.uniform(-0.6, -0.4)
      vel_start=0
      state=[loc_start, vel_start]
      ep_state=[]
      ep_state.append(state)
      ep_reward=[]
      ep_reward.append(0)
      ep_aidx=[]
      a_idx=self.e_greedy_selection(state, eps=0)
      ep_aidx.append(a_idx)
      step=0
      termin_step=np.inf
      while True:
        if step<termin_step: #progress
          state=ep_state[-1]
          a_idx=ep_aidx[-1]
          state_f, reward, termination=self.progression(state, a_idx)
          ep_reward.append(reward)
          #print("Step: {:d} Loc: {:.3f} Vel: {:.3f}".format(step, state[0], state[1]))
          if termination:
            termin_step=step+1
          else:
            ep_state.append(state_f)
            a_idx_f=self.e_greedy_selection(state_f, eps=0)
            ep_aidx.append(a_idx_f)
        update_step=step-(n-1)
        if update_step>=0:
          n_step_return=0
          for t in range(update_step+1, min(termin_step, update_step+n)+1): #iteration for t+1
            n_step_return+=gamma**(t-(update_step+1))*ep_reward[t]
          if update_step+n<termin_step:
            n_step_return+=gamma**n*self.get_action_value(ep_state[update_step+n],ep_aidx[update_step+n])
          q=self.get_action_value(ep_state[update_step],ep_aidx[update_step])
          fv=self.get_feature_vector(ep_state[update_step], ep_aidx[update_step])
          self.weight=self.weight+step_size*(n_step_return-q)*fv
        if update_step+1==termin_step:
          break
        else:
          step+=1
      #if epoch%(iter/20)==0:
      print("Epoch: {:d}, Episode Length: {:d}, Weight Vector Sum: {:.3f}".format(epoch, step, torch.sum(self.weight).item()))
    return self.weight

  def test(self):
    ep_s=[]
    ep_r=[]
    loc_start=random.uniform(-0.6, -0.4)
    vel_start=0
    state=[loc_start, vel_start]
    ep_s.append(state)
    ep_r.append(0) #initiate reward sequence
    while True:
      state=ep_s[-1]
      a_idx=self.e_greedy_selection(state)
      state_f, reward, termination=self.progression(state, a_idx)
      ep_s.append(state_f)
      ep_r.append(reward)
      if termination:
        break
    return ep_s, ep_r

s_dim=2
bounds=[[-1.2,0.5],[-0.07,0.07]]
n_tiles=[8,8] #No. of tiles for each dimension
n_tilings=8

mountain_car=Mountain_Car(s_dim, bounds, n_tilings, n_tiles)
weight=mountain_car.n_step_Sarsa(n=2, iter=100, step_size=0.1/8)

#1-step ver
mountain_car_1=Mountain_Car()
weight=mountain_car_1.train()
ep_s=mountain_car_1.test()
loc_list=[]
vel_list=[]
ep_length=len(ep_s)
time_list=np.arange(0,ep_length,1)
for state in ep_s:
  loc_list.append(state[0])
  vel_list.append(state[1])
plt.figure(0)
plt.plot(time_list, loc_list, 'b', linewidth=1.5)
plt.xlabel("Time")
plt.ylabel("Location")
plt.title("1-Step Semi-Gradient Sarsa: Location")

plt.figure(1)
plt.plot(time_list, vel_list, 'r', linewidth=1.5)
plt.xlabel("Time")
plt.ylabel("Location")
plt.title("1-Step Semi-Gradient Sarsa: Velocity")

#n-step ver
n=8
mountain_car_n=Mountain_Car()
weight=mountain_car_n.n_step_train(n)
ep_s=mountain_car_n.test()
for state in ep_s:
  loc_list.append(state[0])
  vel_list.append(state[1])
plt.figure(0)
plt.plot(time_list, loc_list, 'b', linewidth=1.5)
plt.xlabel("Time")
plt.ylabel("Location")
plt.title("{:d}-Step Semi-Gradient Sarsa: Location".format(n))

plt.figure(1)
plt.plot(time_list, vel_list, 'r', linewidth=1.5)
plt.xlabel("Time")
plt.ylabel("Location")
plt.title("{:d}-Step Semi-Gradient Sarsa: Velocity".format(n))

print(weight)
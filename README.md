# sutton-barto-rl-intro
Codes for examples and exercises in "Reinforcement Learning: An Introduction" by Sutton &amp; Barto

Examples and exercises: specific reference from the book provided below
1. k_armed_bandit.py: Ch.2 Multi-armed Bandits pp.25~40
2. dp_gridworld_policy_evaluation.py: Ch.3 Example 3.8 pp.65
3. dp_car_rental.py: Ch.4 Example 4.2 pp.81
4. dp_gridworld2.py: Ch.4 Figure 4.1 pp.77
5. gambler: Ch.4 Example 4.3 pp.84 #Revising
6. mc_blackjack.py: Ch.5 Example 5.1 pp.93
7. mc_blackjack_off_policy.py: Ch.5 Example 5.4 pp.105
8. mc_racetrack.py: Ch.5 Exercise 5.10 pp.111
9. td_mrp.py: Ch.6 Example 6.2 pp.125
10. td_windy_gridworld.py: Ch.6 Example 6.5 pp.130 + Exercise 6.9 and 6.10
11. td_cliffwalking.py: Ch.6 Example 6.6 pp.132
12. ntd_windy_gridworld.py: Ch.7 problem: Figure 7.4 (pp.147) -> solve using n-step Sarsa & classic off-policy n-step TD
13. ntd_windy_gridworld2.py: Ch.7 problem: Figure 7.4-> solve using off-policy n-step TD with covariates & n-step tree backup
14. ntd_windy_gridworld_q(sigma).py: Ch.7 problem: Figure 7.4 -> solve using Q(sigma) algorithm
15. planning_dynaq_maze.py: Ch.8 Example 8.1 pp.164
16. rl_on_policy_ftn_approx.py: Ch.9 Example 9.3 pp.235
17. rl_mountain_car.py: Ch.10 Example 10.1 pp.244-245 /using n-step Sarsa
18. rl_access_control.py: Ch.10 Example 10.2 pp.251
19. rl_baird's_counterexample.py: Ch.11 Exercise 11.3 pp.266
20. rl_gradient_td.py: Ch.11 Figure 11.5 pp.282 (Gradient TD on Baird's Counterexample)
21. rl_mountain_car_et.py: Ch.12 Figure 12.11 pp.308 (using Sarsa(lambda) and True-Online Sarsa)
22. rl_pg_methods.py: Ch.13 Figure 13.2 pp.332
